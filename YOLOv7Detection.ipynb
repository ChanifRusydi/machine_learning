{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChanifRusydi/machine_learning/blob/main/YOLOv7Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "msS1ksMCbcOZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version: 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)], sys.version_info(major=3, minor=8, micro=5, releaselevel='final', serial=0) \n",
            "Pytorch version: 1.12.0 \n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version: {sys.version}, {sys.version_info} \")\n",
        "print(f\"Pytorch version: {torch.__version__} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yCnuiIXjbcLq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Dec 13 15:42:50 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.06       Driver Version: 510.06       CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A    0C    P8    N/A /  N/A |     75MiB /  4096MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZAmXf2Bvqbq"
      },
      "outputs": [],
      "source": [
        "%%cmd\n",
        "chdir .\\Documents\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "utxvpmuibcI7"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (4293971979.py, line 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Input \u001b[1;32mIn [8]\u001b[1;36m\u001b[0m\n\u001b[1;33m    git clone https://github.com/WongKinYiu/yolov7\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Download YOLOv7 code\n",
        "%%cmd\n",
        "git clone https://github.com/WongKinYiu/yolov7\n",
        "cd yolov7\n",
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1139, done.\u001b[K\n",
            "remote: Total 1139 (delta 0), reused 0 (delta 0), pack-reused 1139\u001b[K\n",
            "Receiving objects: 100% (1139/1139), 70.32 MiB | 3.63 MiB/s, done.\n",
            "Resolving deltas: 100% (512/512), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "!cd yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(weights=['yolov7.pt'], source='0', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 2.0.0 CPU\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "1/1: 0... [ WARN:0@10.399] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
            " success (1280x720 at 30.00 FPS).\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/chanifrusydi/machine_learning/yolov7/detect.py\", line 196, in <module>\n",
            "    detect()\n",
            "  File \"/Users/chanifrusydi/machine_learning/yolov7/detect.py\", line 55, in detect\n",
            "    dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
            "  File \"/Users/chanifrusydi/machine_learning/yolov7/utils/datasets.py\", line 302, in __init__\n",
            "    s = np.stack([letterbox(x, self.img_size, stride=self.stride)[0].shape for x in self.imgs], 0)  # shapes\n",
            "  File \"/Users/chanifrusydi/machine_learning/yolov7/utils/datasets.py\", line 302, in <listcomp>\n",
            "    s = np.stack([letterbox(x, self.img_size, stride=self.stride)[0].shape for x in self.imgs], 0)  # shapes\n",
            "  File \"/Users/chanifrusydi/machine_learning/yolov7/utils/datasets.py\", line 986, in letterbox\n",
            "    shape = img.shape[:2]  # current shape [height, width]\n",
            "AttributeError: 'NoneType' object has no attribute 'shape'\n"
          ]
        }
      ],
      "source": [
        "!python yolov7/detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KhApWfeKbcFG"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (2062427387.py, line 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m\u001b[0m\n\u001b[1;33m    wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Download trained weights\n",
        "%%cmd\n",
        "wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('yolov7.pt', <http.client.HTTPMessage at 0x1873e614340>)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve('https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt', 'yolov7.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xI5DiyI2bcAK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "python: can't open file 'detect.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Detection\n",
        "!python detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source inference/images/horses.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='image.png', update=False, view_img=False, weights=['yolov7.pt'])\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "3 cars, 3 trucks, Done. (72.0ms) Inference, (87.7ms) NMS\n",
            " The image with the result is saved in: runs\\detect\\exp3\\image.png\n",
            "Done. (0.473s)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOR  v0.1-116-g8c0bf3f torch 1.12.1 CUDA:0 (NVIDIA GeForce GTX 1050, 4095.875MB)\n",
            "\n",
            "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients\n",
            "c:\\Users\\user\\miniconda3\\lib\\site-packages\\torch\\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2895.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "# Detection\n",
        "!python yolov7/detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source image.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp7rVA0nbn-O"
      },
      "outputs": [],
      "source": [
        "# define helper functions to show images\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aId1iLXtb7KA"
      },
      "outputs": [],
      "source": [
        "imShow(\"runs/detect/exp/horses.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHNexgAZt5Ch"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from IPython.display import display, Image\n",
        "import ipywidgets as widgets\n",
        "import threading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aghWGuat-U3"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(3,640) # adjust width\n",
        "cap.set(4,480) # adjust height\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    cv2.imshow(\"Webcam\", img) # This will open an independent window\n",
        "    if cv2.waitKey(1) & 0xFF==ord('q'): # quit when 'q' is pressed\n",
        "        cap.release()\n",
        "        break\n",
        "        \n",
        "cv2.destroyAllWindows() \n",
        "cv2.waitKey(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Microsoft Windows [Version 10.0.19044.2251]\n",
            "(c) Microsoft Corporation. All rights reserved.\n",
            "\n",
            "(base) c:\\Users\\User\\Documents\\machine_learning>git clone https://github.com/WongKinYiu/yolov7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov7'...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "(base) c:\\Users\\User\\Documents\\machine_learning>"
          ]
        }
      ],
      "source": [
        "%%cmd\n",
        "git clone https://github.com/WongKinYiu/yolov7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\user\\Documents\\machine_learning\\YOLOv7Detection.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/machine_learning/YOLOv7Detection.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Documents/machine_learning/YOLOv7Detection.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(device)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='0', update=False, view_img=False, weights=['yolov7.pt'])\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "1/1: 0...  success (640x480 at 30.00 FPS).\n",
            "\n",
            "0: 2 persons, 2 beds, 1 cell phone, Done. (83.3ms) Inference, (52.0ms) NMS\n",
            "0: 2 persons, 2 beds, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.9ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.4ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.7ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (83.8ms) Inference, (1.0ms) NMS\n",
            "0: 1 person, Done. (83.9ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, 1 bed, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, 1 bed, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, 1 bed, 1 remote, Done. (84.3ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, 1 bed, 1 remote, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (84.3ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (87.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (82.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.3ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.7ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.9ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.4ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.5ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.7ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (82.8ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (82.3ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, 1 bed, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, 1 bed, Done. (82.8ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (82.6ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.0ms) Inference, (6.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (83.9ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (85.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (84.4ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (85.3ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (82.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.1ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.8ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.3ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (82.8ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.1ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (84.6ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (84.2ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 couch, Done. (83.7ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.9ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (82.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.4ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.5ms) Inference, (2.0ms) NMS"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOR  v0.1-116-g8c0bf3f torch 1.12.1 CUDA:0 (NVIDIA GeForce GTX 1050, 4095.875MB)\n",
            "\n",
            "Model Summary: 306 layers, 36905341 parameters, 6652669 gradients\n",
            "c:\\Users\\user\\miniconda3\\lib\\site-packages\\torch\\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2895.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 1 person, 1 bed, Done. (84.1ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.5ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.1ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 pizza, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 pizza, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.3ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.2ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.3ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 donut, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 donut, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 donut, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (82.9ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.2ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 pizza, 1 bed, Done. (83.1ms) Inference, (5.0ms) NMS\n",
            "0: 1 person, 1 pizza, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 pizza, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.6ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.1ms) Inference, (6.0ms) NMS\n",
            "0: 1 person, Done. (85.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, Done. (83.1ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.6ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 cell phone, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 cell phone, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.7ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.8ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, Done. (82.7ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (82.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (85.0ms) Inference, (1.9ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (6.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.6ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (82.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, 1 cell phone, Done. (85.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 bed, 1 cell phone, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (85.6ms) Inference, (2.7ms) NMS\n",
            "0: 1 person, Done. (82.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 cell phone, Done. (83.4ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 cell phone, Done. (82.8ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.2ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, Done. (82.8ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 cell phone, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 cell phone, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.5ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.7ms) Inference, (5.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.1ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, 1 cell phone, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, 1 cell phone, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (85.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.1ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.5ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.8ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.2ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 cell phone, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 cell phone, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (82.4ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (85.3ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 donut, Done. (82.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 donut, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 donut, Done. (85.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, 1 cell phone, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, 1 cell phone, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, 1 cell phone, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (82.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.3ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 couch, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (81.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (82.2ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (81.8ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (5.0ms) NMS\n",
            "0: 1 person, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (82.7ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (6.0ms) NMS\n",
            "0: 1 person, 1 donut, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 donut, 1 bed, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.4ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (81.7ms) Inference, (5.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.9ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.2ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (81.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (82.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (82.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.2ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (81.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.5ms) Inference, (2.3ms) NMS\n",
            "0: 2 persons, Done. (82.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (82.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (81.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (81.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.4ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (81.0ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.4ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (81.5ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.5ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (81.0ms) Inference, (7.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.3ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (81.6ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (82.2ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (82.9ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.2ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (81.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (82.4ms) Inference, (3.4ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, 1 remote, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, 1 remote, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.9ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, Done. (82.7ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (82.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.9ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (82.5ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (83.0ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.2ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.2ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.3ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 donut, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 donut, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 donut, 1 couch, Done. (87.0ms) Inference, (3.0ms) NMS\n",
            "0: 1 person, 1 donut, 1 couch, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 donut, Done. (86.6ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 donut, Done. (83.8ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 donut, Done. (87.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 donut, 1 book, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 donut, 1 book, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (87.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.7ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.5ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.9ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 1 person, 1 bed, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (84.2ms) Inference, (2.8ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (84.5ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 bed, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.9ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (88.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.9ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.4ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.7ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.1ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.8ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.4ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (83.3ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.2ms) Inference, (6.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.3ms) Inference, (1.7ms) NMS\n",
            "0: 2 persons, Done. (84.7ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (3.0ms) NMS\n",
            "0: 3 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 3 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 3 persons, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, 1 remote, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 remote, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, 1 donut, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 donut, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 donut, Done. (85.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.7ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.4ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.8ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.3ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.1ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.4ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.8ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (82.9ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.9ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.4ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.7ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.8ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (82.8ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.8ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.5ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 remote, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, 1 remote, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, 1 remote, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.3ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.9ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.3ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.1ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.3ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.1ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.3ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.8ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.3ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.4ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.3ms) Inference, (6.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.1ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (86.1ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.5ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (82.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (82.7ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.9ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.4ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.9ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (84.1ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.3ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (82.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.5ms) Inference, (5.0ms) NMS\n",
            "0: 2 persons, Done. (83.5ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.3ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.8ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.5ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (86.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.6ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.5ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (87.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.4ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (85.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.4ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.2ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (4.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (84.6ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.7ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (84.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (85.0ms) Inference, (2.0ms) NMS\n",
            "0: 2 persons, Done. (83.0ms) Inference, (3.0ms) NMS\n",
            "0: 2 persons, Done. (83.7ms) Inference, (3.0ms) NMS\n",
            "Done. (98.169s)\n"
          ]
        }
      ],
      "source": [
        "!python yolov7/detect.py --weights yolov7.pt --conf 0.25 --img-size 640 --source 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torchinfo\\torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m--> 295\u001b[0m     _ \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39mx, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    296\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1148\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torchvision\\models\\resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[0;32m    269\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[1;32m-> 1148\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[16, 1, 28, 28] to have 3 channels, but got 1 channels instead",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mresnet152()\n\u001b[0;32m      4\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[1;32m----> 5\u001b[0m summary(model, input_size\u001b[39m=\u001b[39;49m(batch_size, \u001b[39m1\u001b[39;49m, \u001b[39m28\u001b[39;49m, \u001b[39m28\u001b[39;49m))\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torchinfo\\torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m validate_user_params(\n\u001b[0;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[0;32m    218\u001b[0m )\n\u001b[0;32m    220\u001b[0m x, correct_input_size \u001b[39m=\u001b[39m process_input(\n\u001b[0;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[0;32m    222\u001b[0m )\n\u001b[1;32m--> 223\u001b[0m summary_list \u001b[39m=\u001b[39m forward_pass(\n\u001b[0;32m    224\u001b[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    225\u001b[0m )\n\u001b[0;32m    226\u001b[0m formatting \u001b[39m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[0;32m    227\u001b[0m results \u001b[39m=\u001b[39m ModelStatistics(\n\u001b[0;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[0;32m    229\u001b[0m )\n",
            "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\torchinfo\\torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    303\u001b[0m     executed_layers \u001b[39m=\u001b[39m [layer \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m summary_list \u001b[39mif\u001b[39;00m layer\u001b[39m.\u001b[39mexecuted]\n\u001b[1;32m--> 304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecuted layers up to: \u001b[39m\u001b[39m{\u001b[39;00mexecuted_layers\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[39mif\u001b[39;00m hooks:\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
          ]
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "import torchvision\n",
        "model = torchvision.models.resnet152()\n",
        "batch_size = 16\n",
        "summary(model, input_size=(batch_size, 1, 28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "YOLOv7Detection.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "631926b96873d2007fbe5ba14401cac9ce99e5e76ded0bffc18be58f3fefa61b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
