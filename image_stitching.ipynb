{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image1 = cv2.imread(\"image1_60_left.jpg\")\n",
    "image2 = cv2.imread(\"image1_60_right.jpg\")\n",
    "\n",
    "\n",
    "image_stitching = cv2.Stitcher_create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\tempfile.py:255\u001b[0m, in \u001b[0;36m_mkstemp_inner\u001b[1;34m(dir, pre, suf, flags, output_type)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m     fd \u001b[39m=\u001b[39m _os\u001b[39m.\u001b[39;49mopen(file, flags, \u001b[39m0o600\u001b[39;49m)\n\u001b[0;32m    256\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'c:\\\\ProgramData\\\\Miniconda3\\\\lib\\\\site-packages\\\\largestinteriorrectangle\\\\__pycache__\\\\tmphmmwa2_4'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m stitcher \u001b[39m=\u001b[39m Stitcher(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39msettings)\n\u001b[0;32m     12\u001b[0m stitcher \u001b[39m=\u001b[39m stitching\u001b[39m.\u001b[39mStitcher()\n\u001b[1;32m---> 13\u001b[0m panorama \u001b[39m=\u001b[39m stitcher\u001b[39m.\u001b[39;49mstitch([\u001b[39m\"\u001b[39;49m\u001b[39mimage1_60_left.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mimage1_60_right.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m     14\u001b[0m plot_image(panorama, (\u001b[39m20\u001b[39m,\u001b[39m20\u001b[39m))\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\stitching\\stitcher.py:100\u001b[0m, in \u001b[0;36mStitcher.stitch\u001b[1;34m(self, img_names)\u001b[0m\n\u001b[0;32m     98\u001b[0m imgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresize_low_resolution(imgs)\n\u001b[0;32m     99\u001b[0m imgs, masks, corners, sizes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarp_low_resolution(imgs, cameras)\n\u001b[1;32m--> 100\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_cropper(imgs, masks, corners, sizes)\n\u001b[0;32m    101\u001b[0m imgs, masks, corners, sizes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrop_low_resolution(\n\u001b[0;32m    102\u001b[0m     imgs, masks, corners, sizes\n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimate_exposure_errors(corners, imgs, masks)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\stitching\\stitcher.py:176\u001b[0m, in \u001b[0;36mStitcher.prepare_cropper\u001b[1;34m(self, imgs, masks, corners, sizes)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare_cropper\u001b[39m(\u001b[39mself\u001b[39m, imgs, masks, corners, sizes):\n\u001b[1;32m--> 176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcropper\u001b[39m.\u001b[39;49mprepare(imgs, masks, corners, sizes)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\stitching\\cropper.py:57\u001b[0m, in \u001b[0;36mCropper.prepare\u001b[1;34m(self, imgs, masks, corners, sizes)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_crop:\n\u001b[0;32m     56\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimate_panorama_mask(imgs, masks, corners, sizes)\n\u001b[1;32m---> 57\u001b[0m     lir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimate_largest_interior_rectangle(mask)\n\u001b[0;32m     58\u001b[0m     corners \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_zero_center_corners(corners)\n\u001b[0;32m     59\u001b[0m     rectangles \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_rectangles(corners, sizes)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\stitching\\cropper.py:94\u001b[0m, in \u001b[0;36mCropper.estimate_largest_interior_rectangle\u001b[1;34m(self, mask)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mestimate_largest_interior_rectangle\u001b[39m(\u001b[39mself\u001b[39m, mask):\n\u001b[0;32m     92\u001b[0m     \u001b[39m# largestinteriorrectangle is only imported if cropping\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[39m# is explicitly desired (needs some time to compile at the first run!)\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mlargestinteriorrectangle\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     contours, hierarchy \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mfindContours(mask, cv\u001b[39m.\u001b[39mRETR_TREE, cv\u001b[39m.\u001b[39mCHAIN_APPROX_NONE)\n\u001b[0;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m hierarchy\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(hierarchy \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\largestinteriorrectangle\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlir\u001b[39;00m \u001b[39mimport\u001b[39;00m lir, pt1, pt2\n\u001b[0;32m      3\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.2.0\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\largestinteriorrectangle\\lir.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlir_basis\u001b[39;00m \u001b[39mimport\u001b[39;00m largest_interior_rectangle \u001b[39mas\u001b[39;00m lir_basis\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlir_within_contour\u001b[39;00m \u001b[39mimport\u001b[39;00m largest_interior_rectangle \\\n\u001b[0;32m      3\u001b[0m     \u001b[39mas\u001b[39;00m lir_within_contour\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlir_within_polygon\u001b[39;00m \u001b[39mimport\u001b[39;00m largest_interior_rectangle \\\n\u001b[0;32m      5\u001b[0m     \u001b[39mas\u001b[39;00m lir_within_polygon\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\largestinteriorrectangle\\lir_basis.py:13\u001b[0m\n\u001b[0;32m      8\u001b[0m     s_map \u001b[39m=\u001b[39m span_map(grid, h_adjacency, v_adjacency)\n\u001b[0;32m      9\u001b[0m     \u001b[39mreturn\u001b[39;00m biggest_span_in_span_map(s_map)\n\u001b[0;32m     12\u001b[0m \u001b[39m@nb\u001b[39;49m\u001b[39m.\u001b[39;49mnjit(\u001b[39m'\u001b[39;49m\u001b[39muint32[:,::1](boolean[:,::1])\u001b[39;49m\u001b[39m'\u001b[39;49m, parallel\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, cache\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m---> 13\u001b[0m \u001b[39mdef\u001b[39;49;00m \u001b[39mhorizontal_adjacency\u001b[39;49m(grid):\n\u001b[0;32m     14\u001b[0m     result \u001b[39m=\u001b[39;49m np\u001b[39m.\u001b[39;49mzeros((grid\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], grid\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]), dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49muint32)\n\u001b[0;32m     15\u001b[0m     \u001b[39mfor\u001b[39;49;00m y \u001b[39min\u001b[39;49;00m nb\u001b[39m.\u001b[39;49mprange(grid\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]):\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\numba\\core\\decorators.py:234\u001b[0m, in \u001b[0;36m_jit.<locals>.wrapper\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    230\u001b[0m disp \u001b[39m=\u001b[39m dispatcher(py_func\u001b[39m=\u001b[39mfunc, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mlocals\u001b[39m,\n\u001b[0;32m    231\u001b[0m                   targetoptions\u001b[39m=\u001b[39mtargetoptions,\n\u001b[0;32m    232\u001b[0m                   \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdispatcher_args)\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m cache:\n\u001b[1;32m--> 234\u001b[0m     disp\u001b[39m.\u001b[39;49menable_caching()\n\u001b[0;32m    235\u001b[0m \u001b[39mif\u001b[39;00m sigs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     \u001b[39m# Register the Dispatcher to the type inference mechanism,\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[39m# even though the decorator hasn't returned yet.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumba\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m typeinfer\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\numba\\core\\dispatcher.py:863\u001b[0m, in \u001b[0;36mDispatcher.enable_caching\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39menable_caching\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 863\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache \u001b[39m=\u001b[39m FunctionCache(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpy_func)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\numba\\core\\caching.py:601\u001b[0m, in \u001b[0;36mCache.__init__\u001b[1;34m(self, py_func)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39m(py_func)\n\u001b[0;32m    600\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_py_func \u001b[39m=\u001b[39m py_func\n\u001b[1;32m--> 601\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_impl_class(py_func)\n\u001b[0;32m    602\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl\u001b[39m.\u001b[39mlocator\u001b[39m.\u001b[39mget_cache_path()\n\u001b[0;32m    603\u001b[0m \u001b[39m# This may be a bit strict but avoids us maintaining a magic number\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\numba\\core\\caching.py:333\u001b[0m, in \u001b[0;36mCacheImpl.__init__\u001b[1;34m(self, py_func)\u001b[0m\n\u001b[0;32m    331\u001b[0m source_path \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetfile(py_func)\n\u001b[0;32m    332\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_locator_classes:\n\u001b[1;32m--> 333\u001b[0m     locator \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_function(py_func, source_path)\n\u001b[0;32m    334\u001b[0m     \u001b[39mif\u001b[39;00m locator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\numba\\core\\caching.py:180\u001b[0m, in \u001b[0;36m_SourceFileBackedLocatorMixin.from_function\u001b[1;34m(cls, py_func, py_file)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(py_func, py_file)\n\u001b[0;32m    179\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 180\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mensure_cache_path()\n\u001b[0;32m    181\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     \u001b[39m# Cannot ensure the cache directory exists or is writable\u001b[39;00m\n\u001b[0;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\numba\\core\\caching.py:107\u001b[0m, in \u001b[0;36m_CacheLocator.ensure_cache_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    105\u001b[0m os\u001b[39m.\u001b[39mmakedirs(path, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    106\u001b[0m \u001b[39m# Ensure the directory is writable by trying to write a temporary file\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m tempfile\u001b[39m.\u001b[39;49mTemporaryFile(\u001b[39mdir\u001b[39;49m\u001b[39m=\u001b[39;49mpath)\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\tempfile.py:545\u001b[0m, in \u001b[0;36mNamedTemporaryFile\u001b[1;34m(mode, buffering, encoding, newline, suffix, prefix, dir, delete, errors)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39mif\u001b[39;00m _os\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnt\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m delete:\n\u001b[0;32m    543\u001b[0m     flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m _os\u001b[39m.\u001b[39mO_TEMPORARY\n\u001b[1;32m--> 545\u001b[0m (fd, name) \u001b[39m=\u001b[39m _mkstemp_inner(\u001b[39mdir\u001b[39;49m, prefix, suffix, flags, output_type)\n\u001b[0;32m    546\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    547\u001b[0m     file \u001b[39m=\u001b[39m _io\u001b[39m.\u001b[39mopen(fd, mode, buffering\u001b[39m=\u001b[39mbuffering,\n\u001b[0;32m    548\u001b[0m                     newline\u001b[39m=\u001b[39mnewline, encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\tempfile.py:255\u001b[0m, in \u001b[0;36m_mkstemp_inner\u001b[1;34m(dir, pre, suf, flags, output_type)\u001b[0m\n\u001b[0;32m    253\u001b[0m _sys\u001b[39m.\u001b[39maudit(\u001b[39m\"\u001b[39m\u001b[39mtempfile.mkstemp\u001b[39m\u001b[39m\"\u001b[39m, file)\n\u001b[0;32m    254\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m     fd \u001b[39m=\u001b[39m _os\u001b[39m.\u001b[39;49mopen(file, flags, \u001b[39m0o600\u001b[39;49m)\n\u001b[0;32m    256\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     \u001b[39mcontinue\u001b[39;00m    \u001b[39m# try again\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import stitching\n",
    "from stitching import Stitcher\n",
    "\n",
    "def plot_image(img, figsize_in_inches=(5,5)):\n",
    "    fig, ax = plt.subplots(figsize=figsize_in_inches)\n",
    "    ax.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "settings = {\"crop\": False,\"detector\": \"akaze\", \"confidence_threshold\": 0.2, \"warper_type\":\"plane\" }\n",
    "stitcher = Stitcher(**settings)\n",
    "stitcher = stitching.Stitcher()\n",
    "panorama = stitcher.stitch([\"image1_60_left.jpg\", \"image1_60_right.jpg\"])\n",
    "plot_image(panorama, (20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SURF not available\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\compat_ptsetreg.cpp:125: error: (-215:Assertion failed) !err.empty() in function 'CvLevMarq::update'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 402\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    385\u001b[0m     \u001b[39m# video1 = cv.VideoCapture('Video1.mp4')\u001b[39;00m\n\u001b[0;32m    386\u001b[0m     \u001b[39m# video2 = cv.VideoCapture('Video2.mp4')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[39m#     frame1 = video1.grab()\u001b[39;00m\n\u001b[0;32m    400\u001b[0m     \u001b[39m#     frame2 = video2.grab()\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     main(\u001b[39m1\u001b[39;49m,image1,image2)\n\u001b[0;32m    404\u001b[0m     cv\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "Cell \u001b[1;32mIn[9], line 247\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(index, image1, image2)\u001b[0m\n\u001b[0;32m    245\u001b[0m     refine_mask[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    246\u001b[0m adjuster\u001b[39m.\u001b[39msetRefinementMask(refine_mask)\n\u001b[1;32m--> 247\u001b[0m b, cameras \u001b[39m=\u001b[39m adjuster\u001b[39m.\u001b[39;49mapply(features, p, cameras)\n\u001b[0;32m    248\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m b:\n\u001b[0;32m    249\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCamera parameters adjusting failed.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\calib3d\\src\\compat_ptsetreg.cpp:125: error: (-215:Assertion failed) !err.empty() in function 'CvLevMarq::update'\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "EXPOS_COMP_CHOICES = OrderedDict()\n",
    "EXPOS_COMP_CHOICES['gain_blocks'] = cv.detail.ExposureCompensator_GAIN_BLOCKS\n",
    "EXPOS_COMP_CHOICES['gain'] = cv.detail.ExposureCompensator_GAIN\n",
    "EXPOS_COMP_CHOICES['channel'] = cv.detail.ExposureCompensator_CHANNELS\n",
    "EXPOS_COMP_CHOICES['channel_blocks'] = cv.detail.ExposureCompensator_CHANNELS_BLOCKS\n",
    "EXPOS_COMP_CHOICES['no'] = cv.detail.ExposureCompensator_NO\n",
    "\n",
    "BA_COST_CHOICES = OrderedDict()\n",
    "BA_COST_CHOICES['ray'] = cv.detail_BundleAdjusterRay\n",
    "BA_COST_CHOICES['reproj'] = cv.detail_BundleAdjusterReproj\n",
    "BA_COST_CHOICES['affine'] = cv.detail_BundleAdjusterAffinePartial\n",
    "BA_COST_CHOICES['no'] = cv.detail_NoBundleAdjuster\n",
    "\n",
    "FEATURES_FIND_CHOICES = OrderedDict()\n",
    "try:\n",
    "    cv.xfeatures2d_SURF.create() # check if the function can be called\n",
    "    FEATURES_FIND_CHOICES['surf'] = cv.xfeatures2d_SURF.create\n",
    "except (AttributeError, cv.error) as e:\n",
    "    print(\"SURF not available\")\n",
    "# if SURF not available, ORB is default\n",
    "FEATURES_FIND_CHOICES['orb'] = cv.ORB.create\n",
    "try:\n",
    "    FEATURES_FIND_CHOICES['sift'] = cv.SIFT_create\n",
    "except AttributeError:\n",
    "    print(\"SIFT not available\")\n",
    "try:\n",
    "    FEATURES_FIND_CHOICES['brisk'] = cv.BRISK_create\n",
    "except AttributeError:\n",
    "    print(\"BRISK not available\")\n",
    "try:\n",
    "    FEATURES_FIND_CHOICES['akaze'] = cv.AKAZE_create\n",
    "except AttributeError:\n",
    "    print(\"AKAZE not available\")\n",
    "\n",
    "SEAM_FIND_CHOICES = OrderedDict()\n",
    "SEAM_FIND_CHOICES['gc_color'] = cv.detail_GraphCutSeamFinder('COST_COLOR')\n",
    "SEAM_FIND_CHOICES['gc_colorgrad'] = cv.detail_GraphCutSeamFinder('COST_COLOR_GRAD')\n",
    "SEAM_FIND_CHOICES['dp_color'] = cv.detail_DpSeamFinder('COLOR')\n",
    "SEAM_FIND_CHOICES['dp_colorgrad'] = cv.detail_DpSeamFinder('COLOR_GRAD')\n",
    "SEAM_FIND_CHOICES['voronoi'] = cv.detail.SeamFinder_createDefault(cv.detail.SeamFinder_VORONOI_SEAM)\n",
    "SEAM_FIND_CHOICES['no'] = cv.detail.SeamFinder_createDefault(cv.detail.SeamFinder_NO)\n",
    "\n",
    "ESTIMATOR_CHOICES = OrderedDict()\n",
    "ESTIMATOR_CHOICES['homography'] = cv.detail_HomographyBasedEstimator\n",
    "ESTIMATOR_CHOICES['affine'] = cv.detail_AffineBasedEstimator\n",
    "\n",
    "WARP_CHOICES = (\n",
    "    'spherical',\n",
    "    'plane',\n",
    "    'affine',\n",
    "    'cylindrical',\n",
    "    'fisheye',\n",
    "    'stereographic',\n",
    "    'compressedPlaneA2B1',\n",
    "    'compressedPlaneA1.5B1',\n",
    "    'compressedPlanePortraitA2B1',\n",
    "    'compressedPlanePortraitA1.5B1',\n",
    "    'paniniA2B1',\n",
    "    'paniniA1.5B1',\n",
    "    'paniniPortraitA2B1',\n",
    "    'paniniPortraitA1.5B1',\n",
    "    'mercator',\n",
    "    'transverseMercator',\n",
    ")\n",
    "\n",
    "WAVE_CORRECT_CHOICES = OrderedDict()\n",
    "WAVE_CORRECT_CHOICES['horiz'] = cv.detail.WAVE_CORRECT_HORIZ\n",
    "WAVE_CORRECT_CHOICES['no'] = None\n",
    "WAVE_CORRECT_CHOICES['vert'] = cv.detail.WAVE_CORRECT_VERT\n",
    "\n",
    "BLEND_CHOICES = ('multiband', 'feather', 'no',)\n",
    "\n",
    "\n",
    "\n",
    "def get_matcher():\n",
    "    try_cuda = False\n",
    "    matcher_type = 'homography'\n",
    "    match_conf = None\n",
    "    features = 'akaze'\n",
    "    if match_conf is None:\n",
    "        if features == 'orb':\n",
    "            match_conf = 0.3\n",
    "        else:\n",
    "            match_conf = 0.65\n",
    "    else:\n",
    "        match_conf = match_conf\n",
    "    range_width = -1\n",
    "    if matcher_type == \"affine\":\n",
    "        matcher = cv.detail_AffineBestOf2NearestMatcher(False, try_cuda, match_conf)\n",
    "    elif range_width == -1:\n",
    "        matcher = cv.detail_BestOf2NearestMatcher(try_cuda, match_conf)\n",
    "    else:\n",
    "        matcher = cv.detail_BestOf2NearestRangeMatcher(range_width, try_cuda, match_conf)\n",
    "    return matcher\n",
    "\n",
    "\n",
    "def get_compensator():\n",
    "    expos_comp_type = cv.detail.ExposureCompensator_GAIN_BLOCKS\n",
    "    expos_comp_nr_feeds = 1\n",
    "    expos_comp_block_size = 32\n",
    "    # expos_comp_nr_filtering = expos_comp_nr_filtering\n",
    "    if expos_comp_type == cv.detail.ExposureCompensator_CHANNELS:\n",
    "        compensator = cv.detail_ChannelsCompensator(expos_comp_nr_feeds)\n",
    "        # compensator.setNrGainsFilteringIterations(expos_comp_nr_filtering)\n",
    "    elif expos_comp_type == cv.detail.ExposureCompensator_CHANNELS_BLOCKS:\n",
    "        compensator = cv.detail_BlocksChannelsCompensator(\n",
    "            expos_comp_block_size, expos_comp_block_size,\n",
    "            expos_comp_nr_feeds\n",
    "        )\n",
    "        # compensator.setNrGainsFilteringIterations(expos_comp_nr_filtering)\n",
    "    else:\n",
    "        compensator = cv.detail.ExposureCompensator_createDefault(expos_comp_type)\n",
    "    return compensator\n",
    "\n",
    "\n",
    "\n",
    "def main(index,image1,image2):\n",
    "    start_count = 0\n",
    "    time_start=time.time()\n",
    "\n",
    "    img_names = [image1,image2]\n",
    "    side_by_side = cv.hconcat([image1,image2])\n",
    "    cv.imshow('frame', side_by_side)\n",
    "    cv.waitKey(500)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    work_megapix = 2\n",
    "    seam_megapix = 0.5\n",
    "    compose_megapix = -1\n",
    "    conf_thresh = 1.0\n",
    "    ba_refine_mask = 'xxxxx'\n",
    "    wave_correct = cv.detail.WAVE_CORRECT_HORIZ\n",
    "    save_graph = None\n",
    "    if save_graph is None:\n",
    "        save_graph = False\n",
    "    else:\n",
    "        save_graph = True\n",
    "    warp_type = 'plane'\n",
    "    blend_type = 'multiband'\n",
    "    blend_strength = 5\n",
    "    result_name = os.path.join(r\"C:\\Users\\User\\Documents\\machine_learning\\yolov7\\Video\", str(index) + '.jpg')\n",
    "    timelapse = None\n",
    "    if timelapse is not None:\n",
    "        timelapse = True\n",
    "        if timelapse == \"as_is\":\n",
    "            timelapse_type = cv.detail.Timelapser_AS_IS\n",
    "        elif timelapse == \"crop\":\n",
    "            timelapse_type = cv.detail.Timelapser_CROP\n",
    "        else:\n",
    "            print(\"Bad timelapse method\")\n",
    "            exit()\n",
    "    else:\n",
    "        timelapse = False\n",
    "    finder = cv.AKAZE_create()\n",
    "    seam_work_aspect = 1\n",
    "    full_img_sizes = []\n",
    "    features = []\n",
    "    images = []\n",
    "    is_work_scale_set = False\n",
    "    is_seam_scale_set = False\n",
    "    is_compose_scale_set = False\n",
    "    # for frame in video_frames:\n",
    "        \n",
    "    for name in img_names:\n",
    "        full_img = name\n",
    "        if full_img is None:\n",
    "            print(\"Cannot read image \", name)\n",
    "            exit()\n",
    "        full_img_sizes.append((full_img.shape[1], full_img.shape[0]))\n",
    "        if work_megapix < 0:\n",
    "            img = full_img\n",
    "            work_scale = 1\n",
    "            is_work_scale_set = True\n",
    "        else:\n",
    "            if is_work_scale_set is False:\n",
    "                work_scale = min(1.0, np.sqrt(work_megapix * 1e6 / (full_img.shape[0] * full_img.shape[1])))\n",
    "                is_work_scale_set = True\n",
    "            img = cv.resize(src=full_img, dsize=None, fx=work_scale, fy=work_scale, interpolation=cv.INTER_LINEAR_EXACT)\n",
    "        if is_seam_scale_set is False:\n",
    "            if seam_megapix > 0:\n",
    "                seam_scale = min(1.0, np.sqrt(seam_megapix * 1e6 / (full_img.shape[0] * full_img.shape[1])))\n",
    "            else:\n",
    "                seam_scale = 1.0\n",
    "            seam_work_aspect = seam_scale / work_scale\n",
    "            is_seam_scale_set = True\n",
    "        img_feat = cv.detail.computeImageFeatures2(finder, img)\n",
    "        features.append(img_feat)\n",
    "        img = cv.resize(src=full_img, dsize=None, fx=seam_scale, fy=seam_scale, interpolation=cv.INTER_LINEAR_EXACT)\n",
    "        images.append(img)\n",
    "\n",
    "    matcher = get_matcher()\n",
    "    p = matcher.apply2(features)\n",
    "    matcher.collectGarbage()\n",
    "\n",
    "    if save_graph:\n",
    "        with open(save_graph, 'w') as fh:\n",
    "            fh.write(cv.detail.matchesGraphAsString(img_names, p, conf_thresh))\n",
    "\n",
    "    indices = cv.detail.leaveBiggestComponent(features, p, conf_thresh)\n",
    "    img_subset = []\n",
    "    img_names_subset = []\n",
    "    full_img_sizes_subset = []\n",
    "    for i in range(len(indices)):\n",
    "        img_names_subset.append(img_names[indices[i]])\n",
    "        img_subset.append(images[indices[i]])\n",
    "        full_img_sizes_subset.append(full_img_sizes[indices[i]])\n",
    "    images = img_subset\n",
    "    img_names = img_names_subset\n",
    "    full_img_sizes = full_img_sizes_subset\n",
    "    num_images = len(img_names)\n",
    "    # if num_images < 2:\n",
    "    #     print(\"Need more images\")\n",
    "    #     exit()\n",
    "\n",
    "    estimator = cv.detail_HomographyBasedEstimator()\n",
    "    b, cameras = estimator.apply(features, p, None)\n",
    "    if not b:\n",
    "        print(\"Homography estimation failed.\")\n",
    "        exit()\n",
    "    for cam in cameras:\n",
    "        cam.R = cam.R.astype(np.float32)\n",
    "\n",
    "    adjuster = cv.detail_BundleAdjusterRay()\n",
    "    adjuster.setConfThresh(conf_thresh)\n",
    "    refine_mask = np.zeros((3, 3), np.uint8)\n",
    "    if ba_refine_mask[0] == 'x':\n",
    "        refine_mask[0, 0] = 1\n",
    "    if ba_refine_mask[1] == 'x':\n",
    "        refine_mask[0, 1] = 1\n",
    "    if ba_refine_mask[2] == 'x':\n",
    "        refine_mask[0, 2] = 1\n",
    "    if ba_refine_mask[3] == 'x':\n",
    "        refine_mask[1, 1] = 1\n",
    "    if ba_refine_mask[4] == 'x':\n",
    "        refine_mask[1, 2] = 1\n",
    "    adjuster.setRefinementMask(refine_mask)\n",
    "    b, cameras = adjuster.apply(features, p, cameras)\n",
    "    if not b:\n",
    "        print(\"Camera parameters adjusting failed.\")\n",
    "        exit()\n",
    "    focals = []\n",
    "    for cam in cameras:\n",
    "        focals.append(cam.focal)\n",
    "    focals.sort()\n",
    "    if len(focals) % 2 == 1:\n",
    "        warped_image_scale = focals[len(focals) // 2]\n",
    "    else:\n",
    "        warped_image_scale = (focals[len(focals) // 2] + focals[len(focals) // 2 - 1]) / 2\n",
    "    if wave_correct is not None:\n",
    "        rmats = []\n",
    "        for cam in cameras:\n",
    "            rmats.append(np.copy(cam.R))\n",
    "        rmats = cv.detail.waveCorrect(rmats, wave_correct)\n",
    "        for idx, cam in enumerate(cameras):\n",
    "            cam.R = rmats[idx]\n",
    "    corners = []\n",
    "    masks_warped = []\n",
    "    images_warped = []\n",
    "    sizes = []\n",
    "    masks = []\n",
    "    for i in range(0, num_images):\n",
    "        um = cv.UMat(255 * np.ones((images[i].shape[0], images[i].shape[1]), np.uint8))\n",
    "        masks.append(um)\n",
    "\n",
    "    warper = cv.PyRotationWarper(warp_type, warped_image_scale * seam_work_aspect)  # warper could be nullptr?\n",
    "    for idx in range(0, num_images):\n",
    "        K = cameras[idx].K().astype(np.float32)\n",
    "        swa = seam_work_aspect\n",
    "        K[0, 0] *= swa\n",
    "        K[0, 2] *= swa\n",
    "        K[1, 1] *= swa\n",
    "        K[1, 2] *= swa\n",
    "        corner, image_wp = warper.warp(images[idx], K, cameras[idx].R, cv.INTER_LINEAR, cv.BORDER_REFLECT)\n",
    "        corners.append(corner)\n",
    "        sizes.append((image_wp.shape[1], image_wp.shape[0]))\n",
    "        images_warped.append(image_wp)\n",
    "        p, mask_wp = warper.warp(masks[idx], K, cameras[idx].R, cv.INTER_NEAREST, cv.BORDER_CONSTANT)\n",
    "        masks_warped.append(mask_wp.get())\n",
    "\n",
    "    images_warped_f = []\n",
    "    for img in images_warped:\n",
    "        imgf = img.astype(np.float32)\n",
    "        images_warped_f.append(imgf)\n",
    "\n",
    "    compensator = get_compensator()\n",
    "    compensator.feed(corners=corners, images=images_warped, masks=masks_warped)\n",
    "\n",
    "    seam_finder = cv.detail_GraphCutSeamFinder('COST_COLOR')\n",
    "    masks_warped = seam_finder.find(images_warped_f, corners, masks_warped)\n",
    "    compose_scale = 1\n",
    "    corners = []\n",
    "    sizes = []\n",
    "    blender = None\n",
    "    timelapser = None\n",
    "    # https://github.com/opencv/opencv/blob/4.x/samples/cpp/stitching_detailed.cpp#L725 ?\n",
    "    for idx, name in enumerate(img_names):\n",
    "        full_img = cv.imread(name)\n",
    "        if not is_compose_scale_set:\n",
    "            if compose_megapix > 0:\n",
    "                compose_scale = min(1.0, np.sqrt(compose_megapix * 1e6 / (full_img.shape[0] * full_img.shape[1])))\n",
    "            is_compose_scale_set = True\n",
    "            compose_work_aspect = compose_scale / work_scale\n",
    "            warped_image_scale *= compose_work_aspect\n",
    "            warper = cv.PyRotationWarper(warp_type, warped_image_scale)\n",
    "            for i in range(0, len(img_names)):\n",
    "                cameras[i].focal *= compose_work_aspect\n",
    "                cameras[i].ppx *= compose_work_aspect\n",
    "                cameras[i].ppy *= compose_work_aspect\n",
    "                sz = (int(round(full_img_sizes[i][0] * compose_scale)),\n",
    "                    int(round(full_img_sizes[i][1] * compose_scale)))\n",
    "                K = cameras[i].K().astype(np.float32)\n",
    "                roi = warper.warpRoi(sz, K, cameras[i].R)\n",
    "                corners.append(roi[0:2])\n",
    "                sizes.append(roi[2:4])\n",
    "        if abs(compose_scale - 1) > 1e-1:\n",
    "            img = cv.resize(src=full_img, dsize=None, fx=compose_scale, fy=compose_scale,\n",
    "                            interpolation=cv.INTER_LINEAR_EXACT)\n",
    "        else:\n",
    "            img = full_img\n",
    "        _img_size = (img.shape[1], img.shape[0])\n",
    "        K = cameras[idx].K().astype(np.float32)\n",
    "        corner, image_warped = warper.warp(img, K, cameras[idx].R, cv.INTER_LINEAR, cv.BORDER_REFLECT)\n",
    "        mask = 255 * np.ones((img.shape[0], img.shape[1]), np.uint8)\n",
    "        p, mask_warped = warper.warp(mask, K, cameras[idx].R, cv.INTER_NEAREST, cv.BORDER_CONSTANT)\n",
    "        compensator.apply(idx, corners[idx], image_warped, mask_warped)\n",
    "        image_warped_s = image_warped.astype(np.int16)\n",
    "        dilated_mask = cv.dilate(masks_warped[idx], None)\n",
    "        seam_mask = cv.resize(dilated_mask, (mask_warped.shape[1], mask_warped.shape[0]), 0, 0, cv.INTER_LINEAR_EXACT)\n",
    "        mask_warped = cv.bitwise_and(seam_mask, mask_warped)\n",
    "        if blender is None and not timelapse:\n",
    "            blender = cv.detail.Blender_createDefault(cv.detail.Blender_NO)\n",
    "            dst_sz = cv.detail.resultRoi(corners=corners, sizes=sizes)\n",
    "            blend_width = np.sqrt(dst_sz[2] * dst_sz[3]) * blend_strength / 100\n",
    "            if blend_width < 1:\n",
    "                blender = cv.detail.Blender_createDefault(cv.detail.Blender_NO)\n",
    "            elif blend_type == \"multiband\":\n",
    "                blender = cv.detail_MultiBandBlender()\n",
    "                blender.setNumBands((np.log(blend_width) / np.log(2.) - 1.).astype(np.int32))\n",
    "            elif blend_type == \"feather\":\n",
    "                blender = cv.detail_FeatherBlender()\n",
    "                blender.setSharpness(1. / blend_width)\n",
    "            blender.prepare(dst_sz)\n",
    "        elif timelapser is None and timelapse:\n",
    "            timelapser = cv.detail.Timelapser_createDefault(timelapse_type)\n",
    "            timelapser.initialize(corners, sizes)\n",
    "        if timelapse:\n",
    "            ma_tones = np.ones((image_warped_s.shape[0], image_warped_s.shape[1]), np.uint8)\n",
    "            timelapser.process(image_warped_s, ma_tones, corners[idx])\n",
    "            pos_s = img_names[idx].rfind(\"/\")\n",
    "            if pos_s == -1:\n",
    "                fixed_file_name = \"fixed_\" + img_names[idx]\n",
    "            else:\n",
    "                fixed_file_name = img_names[idx][:pos_s + 1] + \"fixed_\" + img_names[idx][pos_s + 1:]\n",
    "            cv.imwrite(fixed_file_name, timelapser.getDst())\n",
    "        else:\n",
    "            blender.feed(cv.UMat(image_warped_s), mask_warped, corners[idx])\n",
    "    time_finish=time.time()\n",
    "    if not timelapse:\n",
    "        result = None\n",
    "        result_mask = None\n",
    "        result, result_mask = blender.blend(result, result_mask)\n",
    "        cv.imwrite(result_name, result)\n",
    "        zoom_x = 600.0 / result.shape[1]\n",
    "        dst = cv.normalize(src=result, dst=None, alpha=255., norm_type=cv.NORM_MINMAX, dtype=cv.CV_8U)\n",
    "        dst = cv.resize(dst, dsize=None, fx=zoom_x, fy=zoom_x)\n",
    "        cv.imshow(result_name, dst)\n",
    "        cv.waitKey()\n",
    "    \n",
    "    \n",
    "    print(time_finish-time_start)\n",
    "    print(\"Done\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # video1 = cv.VideoCapture('Video1.mp4')\n",
    "    # video2 = cv.VideoCapture('Video2.mp4')\n",
    "    # frame_count1 = int(video1.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    # frame_count2 = int(video2.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    # frame_count_list = [frame_count1, frame_count2]\n",
    "    # ret1 = video1.grab()\n",
    "    # ret2 = video2.grab()\n",
    "    # for i in range(min(frame_count_list)):\n",
    "    #     frame_index = int(video1.get(cv.CAP_PROP_POS_FRAMES))\n",
    "    #     print(frame_index)\n",
    "    #     _,frame1 = video1.retrieve()\n",
    "    #     _,frame2 = video2.retrieve()\n",
    "        \n",
    "    #     main(i, frame1,frame2)\n",
    "    #     frame1 = video1.grab()\n",
    "    #     frame2 = video2.grab()\n",
    "    \n",
    "    main(1,image1,image2)\n",
    "        \n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 512, 3)\n",
      "(720, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "image1=cv.imread('50_intersect_left.jpg')\n",
    "image2=cv.imread('50_intersect_right.jpg')\n",
    "print(image1.shape)\n",
    "print(image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1814 1814\n",
      "1814\n",
      "FFMPEG\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "def open_image(index, image1,image2):\n",
    "    # image1 = cv.imread(image1)\n",
    "    # image2 = cv.imread(image2)\n",
    "    # image1 = cv.cvtColor(image1, cv.COLOR_BGR2GRAY )\n",
    "    # image2 = cv.cvtColor(image2, cv.COLOR_BGR2GRAY )\n",
    "    cv.imwrite(os.path.join(r'C:\\Users\\User\\Documents\\machine_learning\\yolov7\\Video', 'frame1.jpg'.format(index)), frame1)\n",
    "    cv.imwrite(os.path.join(r'C:\\Users\\User\\Documents\\machine_learning\\yolov7\\Video', 'frame2.jpg'.format(index)), frame2)\n",
    "    side_by_side = cv.hconcat([frame1, frame2])\n",
    "    cv.imshow('frame', side_by_side)\n",
    "    \n",
    "    cv.waitKey(500)\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    video1 = cv.VideoCapture('Video1.mp4')\n",
    "    video2 = cv.VideoCapture('Video2.mp4')\n",
    "    frame_count1 = int(video1.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    frame_count2 = int(video2.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "    print(frame_count1, frame_count2)\n",
    "    frame_count_list = [frame_count1, frame_count2]\n",
    "    print(min(frame_count_list))\n",
    "    print(video1.getBackendName())\n",
    "    ret1 = video1.grab()\n",
    "    ret2 = video2.grab()\n",
    "    for i in range(10):\n",
    "        frame_index = int(video1.get(cv.CAP_PROP_POS_FRAMES))\n",
    "        print(frame_index)\n",
    "        _,frame1 = video1.retrieve()\n",
    "        _,frame2 = video2.retrieve()\n",
    "        \n",
    "        open_image(i, frame1,frame2)\n",
    "        frame1 = video1.grab()\n",
    "        frame2 = video2.grab()\n",
    "    \n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536, 1228, 3)\n",
      "(1536, 1228, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m cv2\u001b[39m.\u001b[39mresizeWindow(\u001b[39m\"\u001b[39m\u001b[39mResized_Window\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1920\u001b[39m, \u001b[39m1080\u001b[39m)\n\u001b[0;32m     10\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mResized_Window\u001b[39m\u001b[39m\"\u001b[39m, side_by_side)\n\u001b[1;32m---> 11\u001b[0m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m10000\u001b[39;49m)\n\u001b[0;32m     12\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image1 = cv2.imread(\"image1_60_left.jpg\")\n",
    "image2 = cv2.imread(\"image1_60_right.jpg\")\n",
    "print(image1.shape)\n",
    "print(image2.shape)\n",
    "side_by_side = cv2.hconcat([image1, image2])\n",
    "cv2.namedWindow(\"Resized_Window\", cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(\"Resized_Window\", 1920, 1080)\n",
    "cv2.imshow(\"Resized_Window\", side_by_side)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "cap1 = cv2.VideoCapture('Video1.mp4')\n",
    "cap2 = cv2.VideoCapture('Video2.mp4')\n",
    "while cap1.isOpened() or cap2.isOpened():\n",
    "\n",
    "    okay1  , frame1 = cap1.read()\n",
    "    okay2 , frame2 = cap2.read()\n",
    "    print(frame1.shape)\n",
    "    print(frame2.shape)\n",
    "    \n",
    "    if okay1 and okay2:\n",
    "        side_by_side = cv2.hconcat([frame1, frame2])\n",
    "        cv2.namedWindow(\"Resized_Window\", cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow(\"Resized_Window\", 1920, 1080)\n",
    "        cv2.imshow(\"Resized_Window\", side_by_side)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # if okay1:\n",
    "    #     # hsv1 = cv2.cvtColor(frame1 , cv2.COLOR_BGR2GRAY)\n",
    "    #     cv2.imshow('fake' , frame1)\n",
    "\n",
    "    # if okay2:\n",
    "    #     # hsv2 = cv2.cvtColor(frame2 , cv2.COLOR_BGR2GRAY)\n",
    "    #     cv2.imshow('real' , frame2)\n",
    "\n",
    "    # if not okay1 or not okay2:\n",
    "    #     print('Cant read the video , Exit!')\n",
    "    #     break\n",
    "\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "    \n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 512, 3)\n",
      "(720, 512, 3)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/core/src/batch_distance.cpp:282: error: (-215:Assertion failed) (type == CV_8U && dtype == CV_32S) || dtype == CV_32F in function 'batchDistance'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/chanifrusydi/machine_learning/image_stitching.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chanifrusydi/machine_learning/image_stitching.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m BFMatcher \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mBFMatcher(normType \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mNORM_HAMMING,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chanifrusydi/machine_learning/image_stitching.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                          crossCheck \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chanifrusydi/machine_learning/image_stitching.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# # Matching descriptor vectors using Brute Force Matcher\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chanifrusydi/machine_learning/image_stitching.ipynb#X22sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m matches \u001b[39m=\u001b[39m BFMatcher\u001b[39m.\u001b[39;49mmatch(queryDescriptors \u001b[39m=\u001b[39;49m descriptors1,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chanifrusydi/machine_learning/image_stitching.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                           trainDescriptors \u001b[39m=\u001b[39;49m descriptors2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chanifrusydi/machine_learning/image_stitching.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m time_end\u001b[39m=\u001b[39mtime\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chanifrusydi/machine_learning/image_stitching.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Sort them in the order of their distance\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_562_cazh1h/croots/recipe/opencv-suite_1664548333142/work/modules/core/src/batch_distance.cpp:282: error: (-215:Assertion failed) (type == CV_8U && dtype == CV_32S) || dtype == CV_32F in function 'batchDistance'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "image1= cv2.imread(\"50_intersect_left.jpg\", flags=cv2.IMREAD_COLOR)\n",
    "image2= cv2.imread(\"50_intersect_right.jpg\",flags=cv2.IMREAD_COLOR)\n",
    "print(image1.shape)\n",
    "print(image2.shape)\n",
    "BRISK = cv2.SIFT_create()\n",
    "time_start=time.time()\n",
    "\n",
    "keypoints1, descriptors1 = BRISK.detectAndCompute(image1, None)\n",
    "keypoints2, descriptors2 = BRISK.detectAndCompute(image2, None)\n",
    "\n",
    "# create BFMatcher object\n",
    "BFMatcher = cv2.BFMatcher(normType = cv2.NORM_HAMMING,\n",
    "                         crossCheck = True)\n",
    "\n",
    "# # Matching descriptor vectors using Brute Force Matcher\n",
    "matches = BFMatcher.match(queryDescriptors = descriptors1,\n",
    "                          trainDescriptors = descriptors2)\n",
    "time_end=time.time()\n",
    "# Sort them in the order of their distance\n",
    "matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "# Draw first 15 matches\n",
    "output = cv2.drawMatches(img1 = image1,\n",
    "                        keypoints1 = keypoints1,\n",
    "                        img2 = image2,\n",
    "                        keypoints2 = keypoints2,\n",
    "                        matches1to2 = matches[:100],\n",
    "                        outImg = None,\n",
    "                        flags = cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "\n",
    "plt.imshow(output)\n",
    "# plt.savefig(\"BRISK_Video.jpg\")\n",
    "plt.show()\n",
    "print(time_end-time_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "for file in os.listdir(r\"C:\\Users\\User\\Documents\\machine_learning\\yolov7\\Video\"):\n",
    "    print(file)\n",
    "    # frame = cv2.imread(file)\n",
    "    # cv2.imshow(\"frame\",frame)\n",
    "    # if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "    # cv2.destroyAllWindows()   \n",
    "\n",
    "# #     cap = cv2.VideoCapture(input_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 154\u001b[0m\n\u001b[0;32m    152\u001b[0m cv\u001b[39m.\u001b[39mimwrite(\u001b[39m\"\u001b[39m\u001b[39mresult.jpg\u001b[39m\u001b[39m\"\u001b[39m, StitchedImage)\n\u001b[0;32m    153\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[39mif\u001b[39;00m cv\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    155\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def FindHomography(Matches, BaseImage_kp, SecImage_kp):\n",
    "    # If less than 4 matches found, exit the code.\n",
    "    if len(Matches) < 4:\n",
    "        print(\"\\nNot enough matches found between the images.\\n\")\n",
    "        exit(0)\n",
    "\n",
    "    # Storing coordinates of points corresponding to the matches found in both the images\n",
    "    BaseImage_pts = []\n",
    "    SecImage_pts = []\n",
    "    for Match in Matches:\n",
    "        BaseImage_pts.append(BaseImage_kp[Match[0].queryIdx].pt)\n",
    "        SecImage_pts.append(SecImage_kp[Match[0].trainIdx].pt)\n",
    "\n",
    "    # Changing the datatype to \"float32\" for finding homography\n",
    "    BaseImage_pts = np.float32(BaseImage_pts)\n",
    "    SecImage_pts = np.float32(SecImage_pts)\n",
    "\n",
    "    # Finding the homography matrix(transformation matrix).\n",
    "    (HomographyMatrix, Status) = cv.findHomography(SecImage_pts, BaseImage_pts, cv.RANSAC, 4.0)\n",
    "\n",
    "    return HomographyMatrix, Status\n",
    "\n",
    "\n",
    "def GetNewFrameSizeAndMatrix(HomographyMatrix, Sec_ImageShape, Base_ImageShape):\n",
    "    # Reading the size of the image\n",
    "    (Height, Width) = Sec_ImageShape\n",
    "\n",
    "    # Taking the matrix of initial coordinates of the corners of the secondary image\n",
    "    # Stored in the following format: [[x1, x2, x3, x4], [y1, y2, y3, y4], [1, 1, 1, 1]]\n",
    "    # Where (xi, yi) is the coordinate of the i th corner of the image.\n",
    "    InitialMatrix = np.array([[0, Width - 1, Width - 1, 0],\n",
    "                              [0, 0, Height - 1, Height - 1],\n",
    "                              [1, 1, 1, 1]])\n",
    "\n",
    "    # Finding the final coordinates of the corners of the image after transformation.\n",
    "    # NOTE: Here, the coordinates of the corners of the frame may go out of the\n",
    "    # frame(negative values). We will correct this afterwards by updating the\n",
    "    # homography matrix accordingly.\n",
    "    FinalMatrix = np.dot(HomographyMatrix, InitialMatrix)\n",
    "\n",
    "    [x, y, c] = FinalMatrix\n",
    "    x = np.divide(x, c)\n",
    "    y = np.divide(y, c)\n",
    "\n",
    "    # Finding the dimentions of the stitched image frame and the \"Correction\" factor\n",
    "    min_x, max_x = int(round(min(x))), int(round(max(x)))\n",
    "    min_y, max_y = int(round(min(y))), int(round(max(y)))\n",
    "\n",
    "    New_Width = max_x\n",
    "    New_Height = max_y\n",
    "    Correction = [0, 0]\n",
    "    if min_x < 0:\n",
    "        New_Width -= min_x\n",
    "        Correction[0] = abs(min_x)\n",
    "    if min_y < 0:\n",
    "        New_Height -= min_y\n",
    "        Correction[1] = abs(min_y)\n",
    "\n",
    "    # Again correcting New_Width and New_Height\n",
    "    # Helpful when secondary image is overlaped on the left hand side of the Base image.\n",
    "    if New_Width < Base_ImageShape[1] + Correction[0]:\n",
    "        New_Width = Base_ImageShape[1] + Correction[0]\n",
    "    if New_Height < Base_ImageShape[0] + Correction[1]:\n",
    "        New_Height = Base_ImageShape[0] + Correction[1]\n",
    "\n",
    "    # Finding the coordinates of the corners of the image if they all were within the frame.\n",
    "    x = np.add(x, Correction[0])\n",
    "    y = np.add(y, Correction[1])\n",
    "    OldInitialPoints = np.float32([[0, 0],\n",
    "                                   [Width - 1, 0],\n",
    "                                   [Width - 1, Height - 1],\n",
    "                                   [0, Height - 1]])\n",
    "    NewFinalPonts = np.float32(np.array([x, y]).transpose())\n",
    "\n",
    "    # Updating the homography matrix. Done so that now the secondary image completely\n",
    "    # lies inside the frame\n",
    "    HomographyMatrix = cv.getPerspectiveTransform(OldInitialPoints, NewFinalPonts)\n",
    "\n",
    "    return [New_Height, New_Width], Correction, HomographyMatrix\n",
    "\n",
    "\n",
    "ratio_thresh = 0.9\n",
    "\n",
    "image1 = cv.imread('frame1_kiri.jpg')\n",
    "\n",
    "image2 = cv.imread('frame2_kanan.jpg')\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------KAZE--------------------------------#\n",
    "\n",
    "AKAZE = cv.AKAZE_create()  # KAZE, AKAZE, ORB, BRISK, xfeatures2d.SURF\n",
    "\n",
    "keypoints1, descriptors1 = AKAZE.detectAndCompute(image1, None)\n",
    "keypoints2, descriptors2 = AKAZE.detectAndCompute(image2, None)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "descriptors1 = np.float32(descriptors1)\n",
    "descriptors2 = np.float32(descriptors2)\n",
    "\n",
    "FLANN = cv.FlannBasedMatcher(indexParams=index_params,\n",
    "                             searchParams=search_params)\n",
    "\n",
    "matches = FLANN.knnMatch(queryDescriptors=descriptors1,\n",
    "                         trainDescriptors=descriptors2,\n",
    "                         k=2)\n",
    "\n",
    "good_matches = []\n",
    "t = []\n",
    "for m, n in matches:\n",
    "    if m.distance < ratio_thresh * n.distance:\n",
    "        good_matches.append([m])\n",
    "        t.append(m)\n",
    "\n",
    "output = cv.drawMatches(img1=image1,\n",
    "                        keypoints1=keypoints1,\n",
    "                        img2=image2,\n",
    "                        keypoints2=keypoints2,\n",
    "                        matches1to2=t,\n",
    "                        outImg=None,\n",
    "                        flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "cv.namedWindow(\"drawMatches.jpg\")\n",
    "cv.imshow(\"drawMatches.jpg\", output)\n",
    "\n",
    "# ----------------------------------FindHomography-------------------------------------------#\n",
    "\n",
    "HomographyMatrix, Status = FindHomography(good_matches, keypoints1, keypoints2)\n",
    "\n",
    "BaseImage = image1\n",
    "SecImage = image2\n",
    "\n",
    "NewFrameSize, Correction, HomographyMatrix = GetNewFrameSizeAndMatrix(HomographyMatrix, SecImage.shape[:2],\n",
    "                                                                      BaseImage.shape[:2])\n",
    "\n",
    "StitchedImage = cv.warpPerspective(SecImage, HomographyMatrix, (NewFrameSize[1], NewFrameSize[0]))\n",
    "StitchedImage[Correction[1]:Correction[1] + BaseImage.shape[0],\n",
    "Correction[0]:Correction[0] + BaseImage.shape[1]] = BaseImage\n",
    "\n",
    "cv.namedWindow(\"stitched2.jpg\")\n",
    "cv.imshow(\"stitched2.jpg\", StitchedImage)\n",
    "\n",
    "\n",
    "cv.imwrite(\"result.jpg\", StitchedImage)\n",
    "while True:\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
